{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import optuna\n",
    "from optuna.trial import TrialState\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from torchvision import datasets\n",
    "from torchvision import transforms\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "DEVICE = torch.device(\"cpu\")\n",
    "BATCHSIZE = 64\n",
    "CLASSES = 2\n",
    "DIR = os.getcwd()\n",
    "EPOCHS = 30\n",
    "\n",
    "INPUT_SIZE = 1928\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create batched data loaders for training and validation sets\n",
    "train_data = pd.read_csv(\"train_fe.csv\")\n",
    "train_loaders = []\n",
    "val_loaders = []\n",
    "for i in range(5): \n",
    "    train = train_data[train_data.fold != i]\n",
    "    val = train_data[train_data.fold == i]\n",
    "    ss = StandardScaler()\n",
    "\n",
    "    x_train = train.drop([\"target\", \"fold\"], axis=1).to_numpy(dtype=np.float32)\n",
    "    ss.fit(x_train)\n",
    "    x_train = torch.tensor(ss.transform(x_train)) \n",
    "    y_train = torch.LongTensor(train.target.to_numpy(dtype=np.long))\n",
    "\n",
    "    x_valid = torch.tensor(ss.transform(val.drop([\"target\", \"fold\"], axis=1).to_numpy(dtype=np.float32)))\n",
    "    y_valid = torch.LongTensor(val.target.to_numpy(dtype=np.long))\n",
    "\n",
    "    train_ds = TensorDataset(x_train, y_train)\n",
    "    val_ds = TensorDataset(x_valid, y_valid)\n",
    "\n",
    "    train_dl = DataLoader(train_ds, BATCHSIZE, shuffle=True)\n",
    "    val_dl = DataLoader(val_ds, BATCHSIZE, shuffle=True)\n",
    "    \n",
    "    train_loaders.append(train_dl)\n",
    "    val_loaders.append(val_dl)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_def(trial): \n",
    "    \"\"\"\n",
    "    Arhitecture hyperparameters: \n",
    "    - Number of layers\n",
    "    - Number of units per layer\n",
    "    - Dropout rate per layer\n",
    "    - Activation function \n",
    "    \"\"\"\n",
    "\n",
    "    n_layers = trial.suggest_int(\"n_layers\", 1, 6)\n",
    "    layers = []\n",
    "\n",
    "    in_features = INPUT_SIZE\n",
    "    for i in range(n_layers): \n",
    "        out_size = trial.suggest_int(f\"n_units_l{i}\", 4, 128)\n",
    "        layers.append(nn.Linear(in_features, out_size))\n",
    "\n",
    "        activation = trial.suggest_categorical(f\"activation_l{i}\", [\"ReLU\", \"Tanh\", \"Sigmoid\"])\n",
    "        if activation == \"ReLU\": \n",
    "            layers.append(nn.ReLU())\n",
    "        elif activation == \"Tanh\": \n",
    "            layers.append(nn.Tanh())\n",
    "        else: \n",
    "            layers.append(nn.Sigmoid())\n",
    "\n",
    "        p = trial.suggest_float(f\"dropout_l{i}\", 0.1, 0.5)\n",
    "        layers.append(nn.Dropout(p))\n",
    "\n",
    "        in_features = out_size \n",
    "\n",
    "    layers.append(nn.Linear(in_features, CLASSES))\n",
    "    layers.append(nn.LogSoftmax(dim=1))\n",
    "\n",
    "    return nn.Sequential(*layers)\n",
    "\n",
    "def objective(trial):\n",
    "    # Generate one model per fold\n",
    "    models = [model_def(trial).to(DEVICE) for _ in range(5)]\n",
    "\n",
    "    \"\"\"\n",
    "    Training hyperparameters: \n",
    "    - Optimizer\n",
    "    - Learning rate\n",
    "    - Epochs \n",
    "    \"\"\"\n",
    "    # Generate optimizer\n",
    "    optimizer_name = trial.suggest_categorical(\"optimizer\", [\"Adam\", \"RMSprop\", \"SGD\"])\n",
    "    lr = trial.suggest_float(\"lr\", 1e-5, 1e-1, log=True)\n",
    "    optimizers = [getattr(optim, optimizer_name)(models[i].parameters(), lr=lr) for i in range(5)]\n",
    "\n",
    "    # Training of the model.\n",
    "    max_acc = np.float64(0)\n",
    "    for epoch in range(EPOCHS):\n",
    "        val_acc = []\n",
    "        for i in range(5): \n",
    "            models[i].train()\n",
    "\n",
    "            for batch_idx, (data, target) in enumerate(train_loaders[i]): \n",
    "                data, target = data.view(data.size(0), -1).to(DEVICE), target.to(DEVICE)\n",
    "\n",
    "                optimizers[i].zero_grad()\n",
    "                output = models[i](data)\n",
    "\n",
    "                loss = F.nll_loss(output, target)\n",
    "                loss.backward()\n",
    "                optimizers[i].step() \n",
    "        \n",
    "            models[i].eval() \n",
    "            correct = 0 \n",
    "            with torch.no_grad(): \n",
    "                for batch_idx, (data, target) in enumerate(val_loaders[i]): \n",
    "                    data, target = data.view(data.size(0), -1).to(DEVICE), target.to(DEVICE)\n",
    "                    output = models[i](data)\n",
    "                    pred = output.argmax(dim=1, keepdim=True)\n",
    "                    correct += pred.eq(target.view_as(pred)).sum().item()\n",
    "            \n",
    "            acc = correct / len(val_loaders[i].dataset)\n",
    "            val_acc.append(acc)\n",
    "        accuracy = np.mean(val_acc)\n",
    "        max_acc = max(accuracy, max_acc)\n",
    "        trial.report(accuracy, epoch)\n",
    "\n",
    "        # Handle pruning based on the intermediate value.\n",
    "        if trial.should_prune():\n",
    "            raise optuna.exceptions.TrialPruned()\n",
    "\n",
    "    return max_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-12-06 02:34:26,857] A new study created in RDB with name: cs467-study4\n",
      "[I 2024-12-06 02:35:34,010] Trial 0 finished with value: 0.6780387455038809 and parameters: {'n_layers': 2, 'n_units_l0': 17, 'activation_l0': 'ReLU', 'dropout_l0': 0.3183910809383067, 'n_units_l1': 19, 'activation_l1': 'Tanh', 'dropout_l1': 0.19776741621483912, 'optimizer': 'Adam', 'lr': 1.809161140458303e-05}. Best is trial 0 with value: 0.6780387455038809.\n",
      "[I 2024-12-06 02:37:08,209] Trial 1 finished with value: 0.6353942071054458 and parameters: {'n_layers': 4, 'n_units_l0': 82, 'activation_l0': 'ReLU', 'dropout_l0': 0.3778078694195257, 'n_units_l1': 42, 'activation_l1': 'Sigmoid', 'dropout_l1': 0.11553339335009066, 'n_units_l2': 36, 'activation_l2': 'ReLU', 'dropout_l2': 0.46132845988020016, 'n_units_l3': 98, 'activation_l3': 'ReLU', 'dropout_l3': 0.43463902383546105, 'optimizer': 'SGD', 'lr': 0.0027320061895683098}. Best is trial 0 with value: 0.6780387455038809.\n",
      "[I 2024-12-06 02:38:07,242] Trial 2 finished with value: 0.6754820470751562 and parameters: {'n_layers': 1, 'n_units_l0': 45, 'activation_l0': 'Tanh', 'dropout_l0': 0.3959969589399681, 'optimizer': 'RMSprop', 'lr': 0.003778837839066473}. Best is trial 0 with value: 0.6780387455038809.\n",
      "[I 2024-12-06 02:39:18,148] Trial 3 finished with value: 0.681229759575945 and parameters: {'n_layers': 2, 'n_units_l0': 80, 'activation_l0': 'Sigmoid', 'dropout_l0': 0.2090290109671941, 'n_units_l1': 54, 'activation_l1': 'Sigmoid', 'dropout_l1': 0.357555517689536, 'optimizer': 'Adam', 'lr': 5.64800327458002e-05}. Best is trial 3 with value: 0.681229759575945.\n",
      "[I 2024-12-06 02:40:25,078] Trial 4 finished with value: 0.6078272648871501 and parameters: {'n_layers': 5, 'n_units_l0': 62, 'activation_l0': 'Sigmoid', 'dropout_l0': 0.3042127552961147, 'n_units_l1': 61, 'activation_l1': 'ReLU', 'dropout_l1': 0.288778589459614, 'n_units_l2': 53, 'activation_l2': 'ReLU', 'dropout_l2': 0.3316947768871096, 'n_units_l3': 119, 'activation_l3': 'Sigmoid', 'dropout_l3': 0.2565601677154927, 'n_units_l4': 80, 'activation_l4': 'Sigmoid', 'dropout_l4': 0.4051185378478462, 'optimizer': 'SGD', 'lr': 0.00010088990165144177}. Best is trial 3 with value: 0.681229759575945.\n",
      "[I 2024-12-06 02:41:33,486] Trial 5 finished with value: 0.6788491617761511 and parameters: {'n_layers': 1, 'n_units_l0': 114, 'activation_l0': 'Sigmoid', 'dropout_l0': 0.11411655941025467, 'optimizer': 'Adam', 'lr': 7.785146341886835e-05}. Best is trial 3 with value: 0.681229759575945.\n",
      "[I 2024-12-06 02:41:35,935] Trial 6 pruned. \n",
      "[I 2024-12-06 02:42:39,769] Trial 7 finished with value: 0.6818100586861866 and parameters: {'n_layers': 2, 'n_units_l0': 66, 'activation_l0': 'Tanh', 'dropout_l0': 0.3893730638121804, 'n_units_l1': 80, 'activation_l1': 'Sigmoid', 'dropout_l1': 0.29020978457814145, 'optimizer': 'RMSprop', 'lr': 2.490108577893982e-05}. Best is trial 7 with value: 0.6818100586861866.\n",
      "[I 2024-12-06 02:43:47,752] Trial 8 finished with value: 0.6783848888327969 and parameters: {'n_layers': 4, 'n_units_l0': 12, 'activation_l0': 'ReLU', 'dropout_l0': 0.2808465560997337, 'n_units_l1': 121, 'activation_l1': 'ReLU', 'dropout_l1': 0.4744208683863884, 'n_units_l2': 82, 'activation_l2': 'ReLU', 'dropout_l2': 0.22199517105212055, 'n_units_l3': 114, 'activation_l3': 'Sigmoid', 'dropout_l3': 0.48251615886075583, 'optimizer': 'RMSprop', 'lr': 0.0003856833940704257}. Best is trial 7 with value: 0.6818100586861866.\n",
      "[I 2024-12-06 02:43:50,035] Trial 9 pruned. \n",
      "[I 2024-12-06 02:43:52,540] Trial 10 pruned. \n",
      "[I 2024-12-06 02:43:55,021] Trial 11 pruned. \n",
      "[I 2024-12-06 02:45:03,475] Trial 12 finished with value: 0.6785008308617824 and parameters: {'n_layers': 3, 'n_units_l0': 57, 'activation_l0': 'Sigmoid', 'dropout_l0': 0.19709156520575016, 'n_units_l1': 81, 'activation_l1': 'Sigmoid', 'dropout_l1': 0.380620317708783, 'n_units_l2': 5, 'activation_l2': 'Tanh', 'dropout_l2': 0.4753895102006849, 'optimizer': 'Adam', 'lr': 0.0007659199637447136}. Best is trial 7 with value: 0.6818100586861866.\n",
      "[I 2024-12-06 02:46:15,883] Trial 13 finished with value: 0.681693695967691 and parameters: {'n_layers': 2, 'n_units_l0': 99, 'activation_l0': 'Tanh', 'dropout_l0': 0.21323634683974826, 'n_units_l1': 45, 'activation_l1': 'Sigmoid', 'dropout_l1': 0.39843907618694907, 'optimizer': 'Adam', 'lr': 4.219103000444565e-05}. Best is trial 7 with value: 0.6818100586861866.\n",
      "[I 2024-12-06 02:46:18,064] Trial 14 pruned. \n",
      "[I 2024-12-06 02:46:23,465] Trial 15 pruned. \n",
      "[I 2024-12-06 02:47:23,174] Trial 16 finished with value: 0.6819825413853305 and parameters: {'n_layers': 2, 'n_units_l0': 38, 'activation_l0': 'Tanh', 'dropout_l0': 0.3480524357010667, 'n_units_l1': 92, 'activation_l1': 'Sigmoid', 'dropout_l1': 0.2796724753027016, 'optimizer': 'RMSprop', 'lr': 0.00024161319128008027}. Best is trial 16 with value: 0.6819825413853305.\n",
      "[I 2024-12-06 02:48:26,857] Trial 17 finished with value: 0.6799508634652196 and parameters: {'n_layers': 3, 'n_units_l0': 35, 'activation_l0': 'Tanh', 'dropout_l0': 0.34759834891313873, 'n_units_l1': 95, 'activation_l1': 'Tanh', 'dropout_l1': 0.26803576143912455, 'n_units_l2': 16, 'activation_l2': 'Tanh', 'dropout_l2': 0.3708240108058216, 'optimizer': 'RMSprop', 'lr': 0.00031610195891572395}. Best is trial 16 with value: 0.6819825413853305.\n",
      "[I 2024-12-06 02:49:21,941] Trial 18 finished with value: 0.6770496203277171 and parameters: {'n_layers': 1, 'n_units_l0': 50, 'activation_l0': 'Tanh', 'dropout_l0': 0.44626924921106376, 'optimizer': 'RMSprop', 'lr': 0.0015912353959802587}. Best is trial 16 with value: 0.6819825413853305.\n",
      "[I 2024-12-06 02:49:24,279] Trial 19 pruned. \n",
      "[I 2024-12-06 02:50:59,654] Trial 20 finished with value: 0.6765304053343429 and parameters: {'n_layers': 5, 'n_units_l0': 69, 'activation_l0': 'Tanh', 'dropout_l0': 0.3312313711438891, 'n_units_l1': 81, 'activation_l1': 'Sigmoid', 'dropout_l1': 0.21633299097063718, 'n_units_l2': 44, 'activation_l2': 'Tanh', 'dropout_l2': 0.4001513807859431, 'n_units_l3': 13, 'activation_l3': 'ReLU', 'dropout_l3': 0.36268998279918263, 'n_units_l4': 7, 'activation_l4': 'Tanh', 'dropout_l4': 0.49144873628058316, 'optimizer': 'RMSprop', 'lr': 0.00020661582983098244}. Best is trial 16 with value: 0.6819825413853305.\n",
      "[I 2024-12-06 02:51:02,039] Trial 21 pruned. \n",
      "[I 2024-12-06 02:52:28,809] Trial 22 finished with value: 0.6808235417849856 and parameters: {'n_layers': 2, 'n_units_l0': 37, 'activation_l0': 'Tanh', 'dropout_l0': 0.3542286740005947, 'n_units_l1': 109, 'activation_l1': 'Sigmoid', 'dropout_l1': 0.42052115857483585, 'optimizer': 'Adam', 'lr': 0.00011049991727439129}. Best is trial 16 with value: 0.6819825413853305.\n",
      "[I 2024-12-06 02:52:31,621] Trial 23 pruned. \n",
      "[I 2024-12-06 02:53:52,514] Trial 24 finished with value: 0.6787903493826382 and parameters: {'n_layers': 3, 'n_units_l0': 56, 'activation_l0': 'Tanh', 'dropout_l0': 0.24942487694722107, 'n_units_l1': 78, 'activation_l1': 'Sigmoid', 'dropout_l1': 0.30165777866918475, 'n_units_l2': 70, 'activation_l2': 'Sigmoid', 'dropout_l2': 0.20480856066936753, 'optimizer': 'RMSprop', 'lr': 0.0006302098863230711}. Best is trial 16 with value: 0.6819825413853305.\n",
      "[I 2024-12-06 02:53:55,139] Trial 25 pruned. \n",
      "[I 2024-12-06 02:55:14,232] Trial 26 finished with value: 0.6795458236048884 and parameters: {'n_layers': 2, 'n_units_l0': 89, 'activation_l0': 'Tanh', 'dropout_l0': 0.2537178675336759, 'n_units_l1': 88, 'activation_l1': 'Sigmoid', 'dropout_l1': 0.16069920868725024, 'optimizer': 'RMSprop', 'lr': 0.00021238423252646562}. Best is trial 16 with value: 0.6819825413853305.\n",
      "[I 2024-12-06 02:55:16,803] Trial 27 pruned. \n",
      "[I 2024-12-06 02:55:18,474] Trial 28 pruned. \n",
      "[I 2024-12-06 02:55:20,680] Trial 29 pruned. \n",
      "[I 2024-12-06 02:55:22,944] Trial 30 pruned. \n",
      "[I 2024-12-06 02:55:25,318] Trial 31 pruned. \n",
      "[I 2024-12-06 02:56:42,365] Trial 32 finished with value: 0.6807060852737636 and parameters: {'n_layers': 2, 'n_units_l0': 86, 'activation_l0': 'Sigmoid', 'dropout_l0': 0.1550751514067865, 'n_units_l1': 52, 'activation_l1': 'Sigmoid', 'dropout_l1': 0.38160871760534476, 'optimizer': 'Adam', 'lr': 0.00040698651365618776}. Best is trial 16 with value: 0.6819825413853305.\n",
      "[I 2024-12-06 02:56:44,678] Trial 33 pruned. \n",
      "[I 2024-12-06 02:56:46,959] Trial 34 pruned. \n",
      "[I 2024-12-06 02:56:49,322] Trial 35 pruned. \n",
      "[I 2024-12-06 02:56:55,188] Trial 36 pruned. \n",
      "[I 2024-12-06 02:56:57,224] Trial 37 pruned. \n",
      "[I 2024-12-06 02:56:59,325] Trial 38 pruned. \n",
      "[I 2024-12-06 02:57:02,296] Trial 39 pruned. \n",
      "[I 2024-12-06 02:57:05,061] Trial 40 pruned. \n",
      "[I 2024-12-06 02:57:07,157] Trial 41 pruned. \n",
      "[I 2024-12-06 02:57:09,290] Trial 42 pruned. \n",
      "[I 2024-12-06 02:58:17,780] Trial 43 finished with value: 0.6825623356681602 and parameters: {'n_layers': 3, 'n_units_l0': 45, 'activation_l0': 'Tanh', 'dropout_l0': 0.33814858557939, 'n_units_l1': 45, 'activation_l1': 'Sigmoid', 'dropout_l1': 0.41601441860582045, 'n_units_l2': 88, 'activation_l2': 'Tanh', 'dropout_l2': 0.32315395376219097, 'optimizer': 'Adam', 'lr': 0.00028092897413284015}. Best is trial 43 with value: 0.6825623356681602.\n",
      "[I 2024-12-06 02:59:25,920] Trial 44 finished with value: 0.6814015691718727 and parameters: {'n_layers': 3, 'n_units_l0': 42, 'activation_l0': 'Tanh', 'dropout_l0': 0.33484702387665166, 'n_units_l1': 47, 'activation_l1': 'Sigmoid', 'dropout_l1': 0.29432514529706677, 'n_units_l2': 89, 'activation_l2': 'Tanh', 'dropout_l2': 0.3405489270891282, 'optimizer': 'Adam', 'lr': 0.00029906368452613}. Best is trial 43 with value: 0.6825623356681602.\n",
      "[I 2024-12-06 03:00:40,798] Trial 45 finished with value: 0.6781531730506299 and parameters: {'n_layers': 4, 'n_units_l0': 41, 'activation_l0': 'Tanh', 'dropout_l0': 0.32313477896165776, 'n_units_l1': 47, 'activation_l1': 'Sigmoid', 'dropout_l1': 0.2892735946277909, 'n_units_l2': 89, 'activation_l2': 'Tanh', 'dropout_l2': 0.33874695470372973, 'n_units_l3': 33, 'activation_l3': 'Tanh', 'dropout_l3': 0.38957977394769017, 'optimizer': 'Adam', 'lr': 0.0010675079781864568}. Best is trial 43 with value: 0.6825623356681602.\n",
      "[I 2024-12-06 03:01:50,302] Trial 46 finished with value: 0.6772252161292358 and parameters: {'n_layers': 3, 'n_units_l0': 51, 'activation_l0': 'Tanh', 'dropout_l0': 0.33600993064342316, 'n_units_l1': 36, 'activation_l1': 'ReLU', 'dropout_l1': 0.495527138017201, 'n_units_l2': 73, 'activation_l2': 'Tanh', 'dropout_l2': 0.3437792757891376, 'optimizer': 'Adam', 'lr': 0.0004957155858811918}. Best is trial 43 with value: 0.6825623356681602.\n",
      "[I 2024-12-06 03:02:54,271] Trial 47 finished with value: 0.6807075156180982 and parameters: {'n_layers': 3, 'n_units_l0': 44, 'activation_l0': 'Tanh', 'dropout_l0': 0.3717153817829452, 'n_units_l1': 21, 'activation_l1': 'Sigmoid', 'dropout_l1': 0.246951755143634, 'n_units_l2': 93, 'activation_l2': 'Tanh', 'dropout_l2': 0.42712025388756036, 'optimizer': 'RMSprop', 'lr': 0.00027255931340171193}. Best is trial 43 with value: 0.6825623356681602.\n",
      "[I 2024-12-06 03:03:59,732] Trial 48 finished with value: 0.6783833743505606 and parameters: {'n_layers': 3, 'n_units_l0': 16, 'activation_l0': 'Tanh', 'dropout_l0': 0.4095036686930737, 'n_units_l1': 61, 'activation_l1': 'Tanh', 'dropout_l1': 0.10414164510338686, 'n_units_l2': 114, 'activation_l2': 'Tanh', 'dropout_l2': 0.3073885725067472, 'optimizer': 'Adam', 'lr': 0.0007574541608930306}. Best is trial 43 with value: 0.6825623356681602.\n",
      "[I 2024-12-06 03:04:02,028] Trial 49 pruned. \n",
      "[I 2024-12-06 03:05:13,404] Trial 50 finished with value: 0.6780957068635495 and parameters: {'n_layers': 3, 'n_units_l0': 64, 'activation_l0': 'Tanh', 'dropout_l0': 0.2995661084630501, 'n_units_l1': 74, 'activation_l1': 'Sigmoid', 'dropout_l1': 0.22087706799166307, 'n_units_l2': 94, 'activation_l2': 'Tanh', 'dropout_l2': 0.2499477244745711, 'optimizer': 'Adam', 'lr': 0.0014095490601445638}. Best is trial 43 with value: 0.6825623356681602.\n",
      "[I 2024-12-06 03:05:15,870] Trial 51 pruned. \n",
      "[I 2024-12-06 03:05:17,911] Trial 52 pruned. \n",
      "[I 2024-12-06 03:05:20,244] Trial 53 pruned. \n",
      "[I 2024-12-06 03:05:22,478] Trial 54 pruned. \n",
      "[I 2024-12-06 03:06:27,861] Trial 55 finished with value: 0.680357838497297 and parameters: {'n_layers': 2, 'n_units_l0': 65, 'activation_l0': 'Tanh', 'dropout_l0': 0.4652550365844225, 'n_units_l1': 8, 'activation_l1': 'Sigmoid', 'dropout_l1': 0.26870540086835704, 'optimizer': 'Adam', 'lr': 0.0005037559825477006}. Best is trial 43 with value: 0.6825623356681602.\n",
      "[I 2024-12-06 03:06:29,786] Trial 56 pruned. \n",
      "[I 2024-12-06 03:07:38,439] Trial 57 finished with value: 0.6786770997665172 and parameters: {'n_layers': 3, 'n_units_l0': 48, 'activation_l0': 'Tanh', 'dropout_l0': 0.23217704892768926, 'n_units_l1': 89, 'activation_l1': 'Sigmoid', 'dropout_l1': 0.4564463691107724, 'n_units_l2': 114, 'activation_l2': 'Tanh', 'dropout_l2': 0.43990782356768654, 'optimizer': 'RMSprop', 'lr': 0.00019298019662457511}. Best is trial 43 with value: 0.6825623356681602.\n",
      "[I 2024-12-06 03:07:40,857] Trial 58 pruned. \n",
      "[I 2024-12-06 03:08:43,234] Trial 59 finished with value: 0.6802411392271933 and parameters: {'n_layers': 2, 'n_units_l0': 54, 'activation_l0': 'Tanh', 'dropout_l0': 0.17444545564009697, 'n_units_l1': 84, 'activation_l1': 'Tanh', 'dropout_l1': 0.34327322516741976, 'optimizer': 'RMSprop', 'lr': 0.0003386935865420541}. Best is trial 43 with value: 0.6825623356681602.\n",
      "[I 2024-12-06 03:08:45,430] Trial 60 pruned. \n",
      "[I 2024-12-06 03:08:47,567] Trial 61 pruned. \n",
      "[I 2024-12-06 03:08:49,771] Trial 62 pruned. \n",
      "[I 2024-12-06 03:08:52,145] Trial 63 pruned. \n",
      "[I 2024-12-06 03:08:54,478] Trial 64 pruned. \n",
      "[I 2024-12-06 03:09:49,019] Trial 65 finished with value: 0.6776294146105466 and parameters: {'n_layers': 1, 'n_units_l0': 46, 'activation_l0': 'Tanh', 'dropout_l0': 0.3261971847211346, 'optimizer': 'RMSprop', 'lr': 0.0001565786658840448}. Best is trial 43 with value: 0.6825623356681602.\n",
      "[I 2024-12-06 03:09:51,165] Trial 66 pruned. \n",
      "[I 2024-12-06 03:09:52,731] Trial 67 pruned. \n",
      "[I 2024-12-06 03:10:56,514] Trial 68 finished with value: 0.6779205317515407 and parameters: {'n_layers': 2, 'n_units_l0': 57, 'activation_l0': 'Tanh', 'dropout_l0': 0.13429331949304446, 'n_units_l1': 52, 'activation_l1': 'Sigmoid', 'dropout_l1': 0.45665353417185583, 'optimizer': 'Adam', 'lr': 0.00040891531069074086}. Best is trial 43 with value: 0.6825623356681602.\n",
      "[I 2024-12-06 03:10:59,146] Trial 69 pruned. \n",
      "[I 2024-12-06 03:11:01,758] Trial 70 pruned. \n",
      "[I 2024-12-06 03:12:05,557] Trial 71 finished with value: 0.6796616814959718 and parameters: {'n_layers': 3, 'n_units_l0': 44, 'activation_l0': 'Tanh', 'dropout_l0': 0.36254318643583583, 'n_units_l1': 15, 'activation_l1': 'Sigmoid', 'dropout_l1': 0.23921353457418998, 'n_units_l2': 92, 'activation_l2': 'Tanh', 'dropout_l2': 0.3650359131217194, 'optimizer': 'RMSprop', 'lr': 0.0006262014001441872}. Best is trial 43 with value: 0.6825623356681602.\n",
      "[I 2024-12-06 03:13:09,099] Trial 72 finished with value: 0.681980522075682 and parameters: {'n_layers': 3, 'n_units_l0': 37, 'activation_l0': 'Tanh', 'dropout_l0': 0.37698730936709357, 'n_units_l1': 23, 'activation_l1': 'Sigmoid', 'dropout_l1': 0.2545057666495172, 'n_units_l2': 97, 'activation_l2': 'Tanh', 'dropout_l2': 0.41578209646065206, 'optimizer': 'RMSprop', 'lr': 0.0002730634299418685}. Best is trial 43 with value: 0.6825623356681602.\n",
      "[I 2024-12-06 03:13:11,426] Trial 73 pruned. \n",
      "[I 2024-12-06 03:14:09,828] Trial 74 finished with value: 0.6817521718095959 and parameters: {'n_layers': 2, 'n_units_l0': 37, 'activation_l0': 'Tanh', 'dropout_l0': 0.3381834386826084, 'n_units_l1': 70, 'activation_l1': 'Sigmoid', 'dropout_l1': 0.2611681591884323, 'optimizer': 'RMSprop', 'lr': 0.00015687925252984465}. Best is trial 43 with value: 0.6825623356681602.\n",
      "[I 2024-12-06 03:14:11,786] Trial 75 pruned. \n",
      "[I 2024-12-06 03:14:14,211] Trial 76 pruned. \n",
      "[I 2024-12-06 03:15:29,016] Trial 77 finished with value: 0.6783257398876759 and parameters: {'n_layers': 3, 'n_units_l0': 101, 'activation_l0': 'Tanh', 'dropout_l0': 0.21179137672227955, 'n_units_l1': 84, 'activation_l1': 'Sigmoid', 'dropout_l1': 0.2932266972379207, 'n_units_l2': 106, 'activation_l2': 'ReLU', 'dropout_l2': 0.3864067828819861, 'optimizer': 'RMSprop', 'lr': 0.0003470040172362423}. Best is trial 43 with value: 0.6825623356681602.\n",
      "[I 2024-12-06 03:15:30,950] Trial 78 pruned. \n",
      "[I 2024-12-06 03:15:33,069] Trial 79 pruned. \n",
      "[I 2024-12-06 03:16:25,694] Trial 80 finished with value: 0.6814017374476766 and parameters: {'n_layers': 1, 'n_units_l0': 36, 'activation_l0': 'Sigmoid', 'dropout_l0': 0.1789373137527231, 'optimizer': 'RMSprop', 'lr': 0.00049632356428946}. Best is trial 43 with value: 0.6825623356681602.\n",
      "[I 2024-12-06 03:17:18,665] Trial 81 finished with value: 0.6800092551692224 and parameters: {'n_layers': 1, 'n_units_l0': 38, 'activation_l0': 'Sigmoid', 'dropout_l0': 0.18050984559132147, 'optimizer': 'RMSprop', 'lr': 0.0006882310583145229}. Best is trial 43 with value: 0.6825623356681602.\n",
      "[I 2024-12-06 03:17:22,141] Trial 82 pruned. \n",
      "[I 2024-12-06 03:17:23,960] Trial 83 pruned. \n",
      "[I 2024-12-06 03:17:25,972] Trial 84 pruned. \n",
      "[I 2024-12-06 03:17:28,274] Trial 85 pruned. \n",
      "[I 2024-12-06 03:18:26,576] Trial 86 finished with value: 0.6809945941397951 and parameters: {'n_layers': 2, 'n_units_l0': 37, 'activation_l0': 'Tanh', 'dropout_l0': 0.2076519445060312, 'n_units_l1': 62, 'activation_l1': 'Sigmoid', 'dropout_l1': 0.23628169794254805, 'optimizer': 'RMSprop', 'lr': 0.0003163514011495273}. Best is trial 43 with value: 0.6825623356681602.\n",
      "[I 2024-12-06 03:18:28,827] Trial 87 pruned. \n",
      "[I 2024-12-06 03:18:30,586] Trial 88 pruned. \n",
      "[I 2024-12-06 03:18:33,184] Trial 89 pruned. \n",
      "[I 2024-12-06 03:18:37,854] Trial 90 pruned. \n",
      "[I 2024-12-06 03:19:37,510] Trial 91 finished with value: 0.6796605035653436 and parameters: {'n_layers': 2, 'n_units_l0': 37, 'activation_l0': 'Tanh', 'dropout_l0': 0.2051195066622065, 'n_units_l1': 62, 'activation_l1': 'Sigmoid', 'dropout_l1': 0.2303821459003857, 'optimizer': 'RMSprop', 'lr': 0.00029935116841396523}. Best is trial 43 with value: 0.6825623356681602.\n",
      "[I 2024-12-06 03:20:36,066] Trial 92 finished with value: 0.6801267116804443 and parameters: {'n_layers': 2, 'n_units_l0': 31, 'activation_l0': 'Tanh', 'dropout_l0': 0.16589272805591607, 'n_units_l1': 69, 'activation_l1': 'Sigmoid', 'dropout_l1': 0.2568259911072547, 'optimizer': 'RMSprop', 'lr': 0.0003729942495720271}. Best is trial 43 with value: 0.6825623356681602.\n",
      "[I 2024-12-06 03:21:36,090] Trial 93 finished with value: 0.6802997833449023 and parameters: {'n_layers': 2, 'n_units_l0': 27, 'activation_l0': 'Tanh', 'dropout_l0': 0.18770184862277062, 'n_units_l1': 63, 'activation_l1': 'Sigmoid', 'dropout_l1': 0.2032384530772822, 'optimizer': 'RMSprop', 'lr': 0.00021668535275755298}. Best is trial 43 with value: 0.6825623356681602.\n",
      "[I 2024-12-06 03:21:38,108] Trial 94 pruned. \n",
      "[I 2024-12-06 03:21:40,939] Trial 95 pruned. \n",
      "[I 2024-12-06 03:21:43,071] Trial 96 pruned. \n",
      "[I 2024-12-06 03:21:45,552] Trial 97 pruned. \n",
      "[I 2024-12-06 03:21:47,800] Trial 98 pruned. \n",
      "[I 2024-12-06 03:21:49,769] Trial 99 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Study statistics: \n",
      "  Number of finished trials:  100\n",
      "  Number of pruned trials:  60\n",
      "  Number of complete trials:  40\n",
      "Best trial:\n",
      "  Value:  0.6825623356681602\n",
      "  Params: \n",
      "    n_layers: 3\n",
      "    n_units_l0: 45\n",
      "    activation_l0: Tanh\n",
      "    dropout_l0: 0.33814858557939\n",
      "    n_units_l1: 45\n",
      "    activation_l1: Sigmoid\n",
      "    dropout_l1: 0.41601441860582045\n",
      "    n_units_l2: 88\n",
      "    activation_l2: Tanh\n",
      "    dropout_l2: 0.32315395376219097\n",
      "    optimizer: Adam\n",
      "    lr: 0.00028092897413284015\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    study = optuna.create_study(direction=\"maximize\",        \n",
    "                                storage=\"sqlite:///db.sqlite3\",  # Specify the storage URL\n",
    "                                study_name=\"cs467-study\"\n",
    "    )\n",
    "    study.optimize(objective, n_trials=100)\n",
    "    \n",
    "\n",
    "    pruned_trials = study.get_trials(deepcopy=False, states=[TrialState.PRUNED])\n",
    "    complete_trials = study.get_trials(deepcopy=False, states=[TrialState.COMPLETE])\n",
    "\n",
    "    print(\"Study statistics: \")\n",
    "    print(\"  Number of finished trials: \", len(study.trials))\n",
    "    print(\"  Number of pruned trials: \", len(pruned_trials))\n",
    "    print(\"  Number of complete trials: \", len(complete_trials))\n",
    "\n",
    "    print(\"Best trial:\")\n",
    "    trial = study.best_trial\n",
    "\n",
    "    print(\"  Value: \", trial.value)\n",
    "\n",
    "    print(\"  Params: \")\n",
    "    for key, value in trial.params.items():\n",
    "        print(\"    {}: {}\".format(key, value))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model(nn.Module): \n",
    "    def __init__(self, input_size): \n",
    "        super(Model, self).__init__()\n",
    "        self.l0 = nn.Linear(input_size, 45)\n",
    "        self.d0 = nn.Dropout(0.33814858557939)\n",
    "        self.l1 = nn.Linear(45, 45)\n",
    "        self.d1 = nn.Dropout(0.41601441860582045)\n",
    "        self.l2 = nn.Linear(45, 88)\n",
    "        self.d2 = nn.Dropout(0.32315395376219097)\n",
    "        self.final = nn.Linear(88, 2)\n",
    "\n",
    "        self.tanh = nn.Tanh()\n",
    "        self.sigmoid = nn.Sigmoid() \n",
    "        self.lsmax = nn.LogSoftmax(dim=1)\n",
    "\n",
    "    def forward(self, x): \n",
    "        x = self.d0(self.tanh(self.l0(x)))\n",
    "        x = self.d1(self.sigmoid(self.l1(x)))\n",
    "        x = self.d2(self.tanh(self.l2(x)))\n",
    "        x = self.lsmax(self.final(x))\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train on full training data, test on test set \n",
    "test_data = pd.read_csv(\"test_fe.csv\")\n",
    "\n",
    "ss_full = StandardScaler()\n",
    "x_train_full = train_data.drop([\"target\", \"fold\"], axis=1).to_numpy(dtype=np.float32)\n",
    "ss_full.fit(x_train_full)\n",
    "x_train_full = torch.tensor(ss.transform(x_train_full))\n",
    "y_train_full = torch.LongTensor(train_data.target.to_numpy())\n",
    "train_dl_full = DataLoader(TensorDataset(x_train_full, y_train_full), BATCHSIZE, shuffle=True)\n",
    "\n",
    "x_test = torch.tensor(ss.transform(test_data.drop([\"target\"], axis=1).to_numpy(dtype=np.float32)))\n",
    "y_test = torch.LongTensor(test_data.target.to_numpy())\n",
    "test_dl = DataLoader(TensorDataset(x_test, y_test), BATCHSIZE, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Model(INPUT_SIZE).to(DEVICE)\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.00028092897413284015)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 training accuracy: 0.6440\n",
      "Epoch 1 training accuracy: 0.6808\n",
      "Epoch 2 training accuracy: 0.6947\n",
      "Epoch 3 training accuracy: 0.6961\n"
     ]
    }
   ],
   "source": [
    "# Training\n",
    "for epoch in range(4):\n",
    "    model.train()\n",
    "\n",
    "    correct = 0 \n",
    "    for batch_idx, (data, target) in enumerate(train_dl_full): \n",
    "        data, target = data.view(data.size(0), -1).to(DEVICE), target.to(DEVICE)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        output = model(data)\n",
    "\n",
    "        pred = output.argmax(dim=1, keepdim=True)\n",
    "        # correct += pred.eq(target.view_as(pred)).sum().item()\n",
    "        correct += (pred.numpy().flatten() == target.numpy()).sum()\n",
    "\n",
    "        loss = F.nll_loss(output, target)\n",
    "        loss.backward()\n",
    "        optimizer.step() \n",
    "\n",
    "    acc = correct / len(train_dl_full.dataset)\n",
    "    print(f\"Epoch {epoch} training accuracy: {acc:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set accuracy: 0.6757\n"
     ]
    }
   ],
   "source": [
    "# Test set\n",
    "model.eval()\n",
    "test_correct = 0 \n",
    "with torch.no_grad(): \n",
    "    for batch_idx, (data, target) in enumerate(test_dl): \n",
    "        data, target = data.view(data.size(0), -1).to(DEVICE), target.to(DEVICE)\n",
    "        output = model(data)\n",
    "        pred = output.argmax(dim=1, keepdim=True)\n",
    "        test_correct += pred.eq(target.view_as(pred)).sum().item()\n",
    "\n",
    "test_acc = test_correct / len(test_dl.dataset)\n",
    "print(f\"Test set accuracy: {test_acc:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save model\n",
    "torch.save(model.state_dict(), 'model.pth')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sig",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
